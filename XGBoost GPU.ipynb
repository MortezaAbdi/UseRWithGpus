{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Demo - GPUs\n",
    "\n",
    "# Setup the data\n",
    "We generate some mock data and create training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Elapsed time =  8.368  seconds"
     ]
    }
   ],
   "source": [
    "# The version of xgboost on this VM has been\n",
    "# compiled to take advantage of GPUs\n",
    "library('xgboost')\n",
    "\n",
    "# Simulate N x p random matrix with some \n",
    "# binomial response dependent on pp columns\n",
    "\n",
    "# 2 Million x 50 matrix\n",
    "N <- 2000000\n",
    "p <- 50\n",
    "pp <- 25\n",
    "\n",
    "pt <- proc.time()\n",
    "\n",
    "X <- matrix(runif(N * p), ncol = p)\n",
    "betas <- 2 * runif(pp) - 1\n",
    "sel <- sort(sample(p, pp))\n",
    "m <- X[, sel] %*% betas - 1 + rnorm(N)\n",
    "y <- rbinom(N, 1, plogis(m))\n",
    "\n",
    "# Create training & validation sets\n",
    "tr <- sample.int(N, N * 0.75)\n",
    "dtrain <- xgb.DMatrix(X[tr,], label = y[tr])\n",
    "dtest <- xgb.DMatrix(X[-tr,], label = y[-tr])\n",
    "wl <- list(train = dtrain, test = dtest)\n",
    "\n",
    "elapsed_time <- (proc.time() - pt)[[\"elapsed\"]]\n",
    "cat(\"\\nElapsed time = \", elapsed_time, \" seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPUs - Start training!\n",
    "\n",
    "The only difference between the CPU version of this code and the GPU version is that the tree_method changes from 'hist' to 'gpu_hist'.  Everything else is identical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Training complete\"\n",
      "\n",
      "Elapsed time =  1.308  seconds"
     ]
    }
   ],
   "source": [
    "# An example of running 'gpu_hist' algorithm\n",
    "# which is\n",
    "# - similar to the 'hist'\n",
    "# - the fastest option for moderately large datasets\n",
    "# - current limitations: max_depth < 16, does not \n",
    "#   implement guided loss\n",
    "\n",
    "pt <- proc.time()\n",
    "\n",
    "param <- list( \n",
    "              objective = 'binary:logistic', \n",
    "              eval_metric = 'auc', \n",
    "              tree_method = 'gpu_hist' # use GPU optimized histogram method\n",
    "             )\n",
    "\n",
    "bst <- xgb.train( \n",
    "                 param, \n",
    "                 dtrain, \n",
    "                 nrounds = 50,\n",
    "                )\n",
    "\n",
    "print(\"Training complete\")\n",
    "\n",
    "elapsed_time <- (proc.time() - pt)[[\"elapsed\"]]\n",
    "cat(\"\\nElapsed time = \", elapsed_time, \" seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
